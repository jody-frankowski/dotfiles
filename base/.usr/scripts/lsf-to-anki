#!/usr/bin/env python3

from requests_html import HTMLSession
import requests
import sys
import urllib

VIDEO_HTML_TEMPLATE="""\
<video autoplay='' loop='' preload='metadata' class='noresize' muted='' style='width: 100%; display: inline-block; height: 100%;'>
<source src='{}'>
<source src='{}'>
</video>
"""
ORG_ANKI_TEMPLATE="""
*** {}
:PROPERTIES:
:ANKI_NOTE_TYPE: Basic (and reversed card)
:SOURCE: {}
:END:

**** Front
{}

{}

**** Back
#+BEGIN_EXPORT html
{}\
#+END_EXPORT\
"""

class Sign:
    def __init__(self):
        self.word = ""
        self.definition = ""
        # Sign videos rendered as html with two sources: the original and an
        # archived one.  Also only the best quality video source is taken from
        # the original.
        self.html_videos = ""
        # A sign may have multiple videos.
        # Videos have multiple sources.
        # So a list of list.
        self.videos_sources = []
        self.url = ""

def archive(url):
    """
    Archives an url on the Wayback Machine (archive.org).
    We don't check if the url is already saved because the Wayback Machine
    already does that for us (even if we don't know how exactly).
    Returns the request object
    """

    session = HTMLSession()
    # For some reasons, unknown to me, the Wayback Machine sometimes redirects
    # (301/302) to the archived page when saving something other than html
    # (eg. mp4) or when the archived page itself redirects. So we always do a
    # first GET, and then GET based on "Content-Location" which is always
    # present (be it a 200 or a 301/302)

    r = session.get('https://web.archive.org/save/' + url)

    if not r.ok:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    r = session.get('https://web.archive.org/' + r.headers['Content-Location'])

    if not r.ok:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    return r

def search_sematos(query):
    """
    TODO check for errors
    Search query on "sematos.eu".
    Returns a list of Sign.
    """

    base_url = "http://www.sematos.eu"

    session = HTMLSession()
    r = session.get(
        base_url + "/lsf-r-{}.html"
        .format(urllib.parse.quote_plus('+'.join(query.split())))
    )

    # When there's only one result we are automatically redirected to the sign page
    if r.url.startswith('http://www.sematos.eu/lsf-p-'):
        sign = Sign()
        sign.url = r.url
        set_infos(sign)
        return [sign]

    results = r.html.find("#resrech li")

    signs = []
    for result in results:
        sign = Sign()
        sign.url = result.find(".qv")[0].attrs['href']
        set_infos(sign)

        signs += [sign]

    return signs


def search_elix(query):
    """
    TODO check for errors
    Search query on "elix-lsf.fr".
    Returns a list of Sign.
    """

    base_url = "https://www.elix-lsf.fr/"

    session = HTMLSession()
    params = {
        'page': 'recherche_definitions',
        'lang': 'fr', 'recherche': '"{}"'.format(query)
    }
    r = session.get(base_url +"/spip.php", params=params)

    definitions_with_sign = r.html.find("a[title='Aller au signe']")

    signs = []
    for definition in definitions_with_sign:
        sign = Sign()
        sign.url = base_url + definition.attrs['href']
        set_infos(sign)

        signs += [sign]

    return signs

def set_infos(sign):
    session = HTMLSession()
    r = session.get(sign.url)

    if r.url.find("elix-lsf.fr") != -1:
        sign.word = r.html.find(".titre_mot")[0].text
        if len(r.html.find(".definition_complete")) >= 1:
            sign.definition = r.html.find(".definition_complete")[0].text
    elif r.url.find("sematos.eu") != -1:
        sign.word = str.capitalize(r.html.find("#titremot")[0].text)
    elif r.url.find("signsuisse.sgb-fss.ch") != -1:
        sign.word = str.capitalize(r.html.find("h1")[0].text)
        sign.definition = r.html.find("h2 ~ p")[1].text
    elif r.url.find("spreadthesign.com") != -1:
        sign.word = r.html.find("h2")[0].text

def source_is_android_compatible(source):
    """
    Returns True if the video source is compatible with android.
    @source can be one of <source> or <video>, it doesn't matter.
    """

    return not ('type' in source.attrs and
        (source.attrs['type'].startswith("video/x-flv") or
        source.attrs['type'].startswith("video/ogg") or
        source.attrs['type'].startswith("video/MP2T")))

def set_videos_sources(sign):
    """
    Should be site agnostic
    For each videos in sign.url add the sources to sign.videos_sources
    """

    session = HTMLSession()
    r = session.get(sign.url)
    videos = r.html.find("video")
    for video in videos:
        sources = []
        # We consider the <video> tag too
        for source in video.find("source")+[video]:
            if 'src' in source.attrs and source_is_android_compatible(source):
                sources += [urllib.parse.urljoin(r.url, source.attrs['src'])]
        sign.videos_sources += [sources]

def best_video_source(sources):
    """
    Returns the "best" video source from a list of sources.
    Size usually isn't the right thing to look for when
    searching for the best quality but it looks like it is
    on some sites because the best quality is at a larger
    resolution and overall size.
    """

    biggest_source_size = 0
    biggest_source_url = None
    for source in sources:
        r = requests.head(source)
        if int(r.headers['Content-Length']) > biggest_source_size:
            biggest_source_size = int(r.headers['Content-Length'])
            biggest_source_url = source

    return biggest_source_url

def generate_html_videos(videos):
    html = ""
    for video in videos:
        html = html + VIDEO_HTML_TEMPLATE.format(
            video['original'],
            video['archived']
        )

    return html

def generate_org_tree(sign):
    return ORG_ANKI_TEMPLATE.format(
        sign.word,
        sign.url,
        sign.word,
        sign.definition,
        sign.html_videos
    )

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: {} WORD...".format(sys.argv[0]))
        sys.exit(-1)

    if sys.argv[1] == "--urls":
        args_urls = True
        sys.argv = sys.argv[2:]
    else:
        args_urls = False
        sys.argv = sys.argv[1:]

    for arg in sys.argv:
        if args_urls:
            sign = Sign()
            sign.url = arg
            set_infos(sign)
            signs = [sign]
        else:
            signs = search_elix(arg)
            signs += search_sematos(arg)

        for sign in signs:
            set_videos_sources(sign)
            archived_sign = archive(sign.url)

            videos = []
            for video_sources in sign.videos_sources:
                video = {}
                # archiving the word/sign page takes care of archiving the
                # videos
                video['original'] = best_video_source(video_sources)
                # get the archived source url by searching for a source that
                # ends with the original url
                video['archived'] = urllib.parse.urljoin(
                    archived_sign.url,
                    archived_sign.html.find(
                        "[src$='{}']".format(video['original'])
                    )[0].attrs['src'].replace("//web", "/web")
                )
                videos += [video]

            sign.html_videos = generate_html_videos(videos)
            org_tree = generate_org_tree(sign)

            print(org_tree)
