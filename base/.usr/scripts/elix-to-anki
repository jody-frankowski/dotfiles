#!/usr/bin/env python3

from requests_html import HTMLSession
import requests
import sys

BASE_URL = "http://www.elix-lsf.fr/"
SEARCH_BASE_URL = BASE_URL + "/spip.php"
VIDEO_HTML_TEMPLATE="""\
<video autoplay='' loop='' preload='metadata' class='noresize' muted='' style='width: 100%; display: inline-block; height: 100%;'>
<source src='{}'>
<source src='{}'>
</video>
"""
ORG_ANKI_TEMPLATE="""
*** {}
:PROPERTIES:
:ANKI_NOTE_TYPE: Basic (and reversed card)
:END:

**** Front
{}
{}

**** Back
#+BEGIN_EXPORT html
{}\
#+END_EXPORT\
"""

class Sign:
    def __init__(self):
        self.word = ""
        self.definition = ""
        # Sign videos rendered as html with two sources: the original and an archived one.
        # Also only the best quality video source is taken from the original.
        self.html_videos = ""
        # A sign may have multiple videos.
        # Videos have multiple sources.
        # So a list of list.
        self.videos_sources = []
        self.url = ""

def archive(url):
    """
    Archives an url on the Wayback Machine (archive.org).
    We don't check if the url is already saved because the Wayback Machine
    already does that for us (even if we don't know how exactly).
    Returns the request object
    """
    session = HTMLSession()
    # For some reasons, unknown to me, the Wayback Machine
    # automatically redirects(302) to the archived page when saving
    # something other than html (eg. mp4) So we only do a head
    # request, which won't be automatically redirected by requests and
    # then do the get on the archived page base on the
    # "Content-Location" header.
    r = session.head('https://web.archive.org/save/' + url)

    if r.status_code != 200:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    r = session.get('https://web.archive.org/' + r.headers['Content-Location'])

    if r.status_code != 200:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    return r

def find_signs(word):
    """
    TODO check for errors
    Search for word on elix.
    On elix, a word may return multiple signs.
    Returns a list of Sign. Only The url field will be filled.
    """

    session = HTMLSession()
    params = {'page': 'recherche_definitions', 'lang': 'fr', 'recherche': '"{}"'.format(word)}
    r = session.get(SEARCH_BASE_URL, params=params)

    words_with_sign = r.html.find("a[title='Aller au signe']")

    signs = []
    for word in words_with_sign:
        sign = Sign()
        sign.url = BASE_URL + word.attrs['href']
        signs += [sign]

    return signs

def get_infos(sign):
    session = HTMLSession()
    r = session.get(sign.url)
    sign.word = r.html.find(".titre_mot")[0].text
    if len(r.html.find(".definition_complete")) >= 1:
        sign.definition = r.html.find(".definition_complete")[0].text

    videos = r.html.find("video")
    for video in videos:
        sources = []
        for source in video.find("source"):
            # Android has trouble reading those :/
            if not (source.attrs['type'].startswith("video/x-flv") or
                    source.attrs['type'].startswith("video/ogg") or
                    source.attrs['type'].startswith("video/MP2T")):
                sources += [source.attrs['src']]
        sign.videos_sources += [sources]

def best_video_source(sources):
    """
    Returns the "best" video source from a list of sources.
    Size usually isn't the right thing to look for when
    searching for the best quality but it looks like it is
    on this particular site because the best quality is at a
    larger resolution and overall size.
    """

    biggest_source_size = 0
    biggest_source_url = None
    for source in sources:
        r = requests.head(source)
        if int(r.headers['Content-Length']) > biggest_source_size:
            biggest_source_size = int(r.headers['Content-Length'])
            biggest_source_url = source

    return biggest_source_url

def generate_html_videos(videos):
    html = ""
    for video in videos:
        html = html + VIDEO_HTML_TEMPLATE.format(video['original'], video['archived'])

    return html

def generate_org_tree(sign):
    return ORG_ANKI_TEMPLATE.format(sign.word, sign.word, sign.definition, sign.html_videos)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: {} WORD...".format(sys.argv[0]))
        sys.exit(-1)

    if sys.argv[1] == "--urls":
        args_urls = True
        sys.argv = sys.argv[2:]
    else:
        args_urls = False
        sys.argv = sys.argv[1:]

    for arg in sys.argv:
        if args_urls:
            sign = Sign()
            sign.url = arg
            signs = [sign]
        else:
            signs = find_signs(arg)

        for sign in signs:
            get_infos(sign)
            archived_sign = archive(sign.url)

            videos = []
            for video_sources in sign.videos_sources:
                video = {}
                # archiving the word/sign page takes care of archiving the videos
                video['original'] = best_video_source(video_sources)
                # get the archived source url by searching for a source that ends with the original url
                video['archived'] = archived_sign.html.find("source[src$='{}']".format(video['original']))[0].attrs['src']
                videos += [video]

            sign.html_videos = generate_html_videos(videos)
            org_tree = generate_org_tree(sign)

            print(org_tree)
