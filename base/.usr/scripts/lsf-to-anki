#!/usr/bin/env python3

from requests_html import HTMLSession
import requests
import sys
import urllib

VIDEO_HTML_TEMPLATE="""\
<video autoplay='' loop='' preload='metadata' class='noresize' muted='' style='width: 100%; display: inline-block; height: 100%;'>
<source src='{}'>
<source src='{}'>
</video>
"""
ORG_ANKI_TEMPLATE="""
*** {}
:PROPERTIES:
:ANKI_NOTE_TYPE: Basic (and reversed card)
:SOURCE: {}
:END:

**** Front
{}
{}

**** Back
#+BEGIN_EXPORT html
{}\
#+END_EXPORT\
"""

class Sign:
    def __init__(self):
        self.word = ""
        self.definition = ""
        # Sign videos rendered as html with two sources: the original and an
        # archived one.  Also only the best quality video source is taken from
        # the original.
        self.html_videos = ""
        # A sign may have multiple videos.
        # Videos have multiple sources.
        # So a list of list.
        self.videos_sources = []
        self.url = ""

def archive(url):
    """
    Archives an url on the Wayback Machine (archive.org).
    We don't check if the url is already saved because the Wayback Machine
    already does that for us (even if we don't know how exactly).
    Returns the request object
    """

    session = HTMLSession()
    # For some reasons, unknown to me, the Wayback Machine
    # automatically redirects(302) to the archived page when saving
    # something other than html (eg. mp4) So we only do a head
    # request, which won't be automatically redirected by requests and
    # then do the get on the archived page base on the
    # "Content-Location" header.
    r = session.head('https://web.archive.org/save/' + url)

    if r.status_code != 200:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    r = session.get('https://web.archive.org/' + r.headers['Content-Location'])

    if r.status_code != 200:
        print(r.url, file=sys.stderr)
        print(r, file=sys.stderr)
        return None

    return r

def search_sematos(query):
    """
    TODO check for errors
    Search query on "sematos.eu".
    Returns a list of Sign.
    """

    base_url = "http://www.sematos.eu"

    session = HTMLSession()
    r = session.get(
        base_url + "/lsf-r-{}.html"
        .format(urllib.parse.quote_plus('+'.join(query.split())))
    )

    # When there's only one result we are automatically redirected to the sign page
    if r.url.startswith('http://www.sematos.eu/lsf-p-'):
        sign = Sign()
        sign.url = r.url
        set_infos(sign)
        return [sign]

    results = r.html.find("#resrech li")

    signs = []
    for result in results:
        sign = Sign()
        sign.url = result.find(".qv")[0].attrs['href']
        set_infos(sign)

        signs += [sign]

    return signs


def search_elix(query):
    """
    TODO check for errors
    Search query on "elix-lsf.fr".
    Returns a list of Sign.
    """

    base_url = "http://www.elix-lsf.fr/"

    session = HTMLSession()
    params = {
        'page': 'recherche_definitions',
        'lang': 'fr', 'recherche': '"{}"'.format(query)
    }
    r = session.get(base_url +"/spip.php", params=params)

    definitions_with_sign = r.html.find("a[title='Aller au signe']")

    signs = []
    for definition in definitions_with_sign:
        sign = Sign()
        sign.url = base_url + definition.attrs['href']
        set_infos(sign)

        signs += [sign]

    return signs

def set_infos(sign):
    session = HTMLSession()
    r = session.get(sign.url)

    if r.url.find("elix-lsf.fr") != -1:
        sign.word = r.html.find(".titre_mot")[0].text
        if len(r.html.find(".definition_complete")) >= 1:
            sign.definition = r.html.find(".definition_complete")[0].text
    elif r.url.find("sematos.eu") != -1:
        sign.word = str.capitalize(r.html.find("#titremot")[0].text)
    elif r.url.find("signsuisse.sgb-fss.ch") != -1:
        sign.word = str.capitalize(r.html.find("h1")[0].text)
        sign.definition = r.html.find("h2 ~ p")[1].text


def set_videos_sources(sign):
    """
    Should be site agnostic
    For each videos in sign.url add the sources to sign.videos_sources
    """

    session = HTMLSession()
    r = session.get(sign.url)
    videos = r.html.find("video")
    for video in videos:
        sources = []
        for source in video.find("source"):
            # Android has trouble reading those :/
            if not (source.attrs['type'].startswith("video/x-flv") or
                    source.attrs['type'].startswith("video/ogg") or
                    source.attrs['type'].startswith("video/MP2T")):
                sources += [urllib.parse.urljoin(r.url, source.attrs['src'])]
        sign.videos_sources += [sources]

def best_video_source(sources):
    """
    Returns the "best" video source from a list of sources.
    Size usually isn't the right thing to look for when
    searching for the best quality but it looks like it is
    on this particular site because the best quality is at a
    larger resolution and overall size.
    """

    biggest_source_size = 0
    biggest_source_url = None
    for source in sources:
        r = requests.head(source)
        if int(r.headers['Content-Length']) > biggest_source_size:
            biggest_source_size = int(r.headers['Content-Length'])
            biggest_source_url = source

    return biggest_source_url

def generate_html_videos(videos):
    html = ""
    for video in videos:
        html = html + VIDEO_HTML_TEMPLATE.format(
            video['original'],
            video['archived']
        )

    return html

def generate_org_tree(sign):
    return ORG_ANKI_TEMPLATE.format(
        sign.word,
        sign.url,
        sign.word,
        sign.definition,
        sign.html_videos
    )

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: {} WORD...".format(sys.argv[0]))
        sys.exit(-1)

    if sys.argv[1] == "--urls":
        args_urls = True
        sys.argv = sys.argv[2:]
    else:
        args_urls = False
        sys.argv = sys.argv[1:]

    for arg in sys.argv:
        if args_urls:
            sign = Sign()
            sign.url = arg
            set_infos(sign)
            signs = [sign]
        else:
            signs = search_elix(arg)
            signs += search_sematos(arg)

        for sign in signs:
            set_videos_sources(sign)
            archived_sign = archive(sign.url)

            videos = []
            for video_sources in sign.videos_sources:
                video = {}
                # archiving the word/sign page takes care of archiving the
                # videos
                video['original'] = best_video_source(video_sources)
                # get the archived source url by searching for a source that
                # ends with the original url
                video['archived'] = archived_sign.html.find(
                    "source[src$='{}']".format(video['original'])
                )[0].attrs['src']
                videos += [video]

            sign.html_videos = generate_html_videos(videos)
            org_tree = generate_org_tree(sign)

            print(org_tree)
